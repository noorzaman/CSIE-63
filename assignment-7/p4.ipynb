{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/IPython/core/magics/pylab.py:161: UserWarning: pylab import has clobbered these variables: ['rand', 'cbrt', 'rank', 'cosh', 'hypot', 'array', 'tan', 'size', 'isnan', 'randn', 'log', 'floor', 'sum', 'sqrt', 'degrees', 'split', 'rint', 'log10', 'sin', 'repeat', 'log2', 'cos', 'ceil', 'broadcast', 'sinh', 'trunc', 'expm1', 'tanh', 'radians', 'exp', 'log1p', 'mean']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pyspark.mllib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot\n",
    "import seaborn as sns\n",
    "import pyspark\n",
    "\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SQLContext, SparkSession, Row\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.mllib.regression import LinearRegressionWithSGD\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.tree import DecisionTree\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "get_ipython().magic(u'pylab inline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Initialize streaming context\n",
    "conf = SparkConf()\\\n",
    "                .setMaster(\"local[2]\")\\\n",
    "                .setAppName(\"AutoRegression\")\\\n",
    "                .set(\"spark.executor.memory\", \"2g\")\n",
    "sc = SparkContext(conf=conf)\n",
    "sc.setLogLevel(\"ERROR\")\n",
    "sqlContext = SQLContext(sc)\n",
    "spark = SparkSession.builder.appName(\"spark play\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['18', '8', '307', '130', '3504', '12', '70', '1', 'chevrolet'], ['15', '8', '350', '165', '3693', '11.5', '70', '1', 'buick'], ['18', '8', '318', '150', '3436', '11', '70', '1', 'plymouth'], ['16', '8', '304', '150', '3433', '12', '70', '1', 'amc'], ['17', '8', '302', '140', '3449', '10.5', '70', '1', 'ford']]\n"
     ]
    }
   ],
   "source": [
    "path = \"file:////Users/swaite/Stirling/CSIE-63/assignment-7/data/auto_mpg_original-1.csv\"\n",
    "df = sc.textFile(path, use_unicode=False) \\\n",
    "                    .map(lambda x: x.split(\",\"))\\\n",
    "                    .filter(lambda x: x[0] > 0.0)\\\n",
    "                    .filter(lambda x: x[3] > 0.0) \\\n",
    "                    \n",
    "print(df.take(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['18', '130', '3504', '12', '70', '1', '8', '307', 'chevrolet'], ['15', '165', '3693', '11.5', '70', '1', '8', '350', 'buick'], ['18', '150', '3436', '11', '70', '1', '8', '318', 'plymouth'], ['16', '150', '3433', '12', '70', '1', '8', '304', 'amc'], ['17', '140', '3449', '10.5', '70', '1', '8', '302', 'ford']]\n"
     ]
    }
   ],
   "source": [
    "#     1. mpg:           continuous\n",
    "#     2. cylinders:     multi-valued discrete\n",
    "#     3. displacement:  continuous\n",
    "#     4. horsepower:    continuous\n",
    "#     5. weight:        continuous\n",
    "#     6. acceleration:  continuous\n",
    "#     7. model year:    multi-valued discrete\n",
    "#     8. origin:        multi-valued discrete\n",
    "#     9. car name:      string (unique for each instance)\n",
    "\n",
    "## Move RDD Order to:\n",
    "\n",
    "#     1. mpg:           continuous\n",
    "#     2. displacement:  continuous\n",
    "#     3. horsepower:    continuous\n",
    "#     4. weight:        continuous\n",
    "#     5. acceleration:  continuous\n",
    "#     6. model year:    multi-valued discrete\n",
    "#     7. origin:        multi-valued discrete\n",
    "#     8. cylinders:     multi-valued discrete\n",
    "#     9. car name:      string (unique for each instance)\n",
    "        \n",
    "df = df.map(lambda x: [\n",
    "                        x[0].replace('NA', \"0.0\"), \n",
    "                        x[2].replace('NA', \"0.0\"), \n",
    "                        x[3].replace('NA', \"0.0\"), \n",
    "                        x[4].replace('NA', \"0.0\"), \n",
    "                        x[5].replace('NA', \"0.0\"), \n",
    "                        x[6].replace('NA', \"0.0\"), \n",
    "                        x[7].replace('NA', \"0.0\"), \n",
    "                        x[1].replace('NA', \"0.0\"), \n",
    "                        x[8].replace('NA', \"0.0\")\n",
    "                    ]) \n",
    "print(df.take(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create feature mappings for categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to get the categorical feature mapping for a given variable column\n",
    "def get_mapping(rdd, idx):\n",
    "    return rdd.map(lambda fields: fields[idx]).distinct().zipWithIndex().collectAsMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature vector length for categorical features: 547\n",
      "Feature vector length for numerical features: 3\n",
      "Total feature vector length: 550\n"
     ]
    }
   ],
   "source": [
    "# extract all the categorical mappings\n",
    "mappings = [get_mapping(df, i) for i in range(1,4)]\n",
    "cat_len = sum(map(len, mappings))\n",
    "num_len = len(df.first()[5:8])\n",
    "total_len = num_len + cat_len\n",
    "print \"Feature vector length for categorical features: %d\" % cat_len \n",
    "print \"Feature vector length for numerical features: %d\" % num_len\n",
    "print \"Total feature vector length: %d\" % total_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Feature Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to use the feature mappings to extract binary feature vectors, and concatenate with\n",
    "# the numerical feature vectors\n",
    "def extract_features(record):\n",
    "    cat_vec = np.zeros(cat_len)\n",
    "    i = 0\n",
    "    step = 0\n",
    "    for field in record[1:4]:\n",
    "        m = mappings[i]\n",
    "        idx = m[field]\n",
    "        cat_vec[idx + step] = 1\n",
    "        i = i + 1\n",
    "        step = step + len(m)\n",
    "    \n",
    "    num_vec = np.array([float(field) for field in record[5:8]])\n",
    "    return np.concatenate((cat_vec, num_vec))\n",
    "\n",
    "# function to extract the label from the last column\n",
    "def extract_label(record):\n",
    "    return float(record[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw data: (18.0,[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,8.0,307.0])\n",
      "Label: 18.0\n",
      "Linear Model feature vector:\n",
      "[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,8.0,307.0]\n",
      "Linear Model feature vector length: 550\n"
     ]
    }
   ],
   "source": [
    "data = df.map(lambda r: LabeledPoint(extract_label(r), extract_features(r)))\n",
    "first_point = data.first()\n",
    "print \"Raw data: \" + str(first_point)\n",
    "print \"Label: \" + str(first_point.label)\n",
    "print \"Linear Model feature vector:\\n\" + str(first_point.features)\n",
    "print \"Linear Model feature vector length: \" + str(len(first_point.features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree feature vector: [3504.0,12.0,70.0,1.0,8.0,307.0]\n",
      "Decision Tree feature vector length: 6\n"
     ]
    }
   ],
   "source": [
    "# we need a separate set of feature vectors for the decision tree\n",
    "def extract_features_dt(record):\n",
    "    return np.array(map(float, record[2:8]))\n",
    "    \n",
    "data_dt = df.map(lambda r: LabeledPoint(extract_label(r), extract_features_dt(r)))\n",
    "first_point_dt = data_dt.first()\n",
    "print \"Decision Tree feature vector: \" + str(first_point_dt.features)\n",
    "print \"Decision Tree feature vector length: \" + str(len(first_point_dt.features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a Regression Model on the Car Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Model predictions: [(18.0, -1.0187537112768575e+35), (15.0, -1.1613490090535328e+35), (18.0, -1.0552325260820744e+35), (16.0, -1.0088061513748944e+35), (17.0, -1.0021725267765866e+35)]\n"
     ]
    }
   ],
   "source": [
    "linear_model = LinearRegressionWithSGD.train(data, iterations=10, step=0.1, intercept=False)\n",
    "true_vs_predicted = data.map(lambda p: (p.label, linear_model.predict(p.features)))\n",
    "print \"Linear Model predictions: \" + str(true_vs_predicted.take(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree predictions: [(18.0, 18.133333333333333), (15.0, 18.133333333333333), (18.0, 18.133333333333333), (16.0, 18.133333333333333), (17.0, 18.133333333333333)]\n",
      "Decision Tree depth: 5\n",
      "Decision Tree number of nodes: 63\n"
     ]
    }
   ],
   "source": [
    "# we pass in an empty mapping for categorical feature size {}\n",
    "dt_model = DecisionTree.trainRegressor(data_dt, {})\n",
    "preds = dt_model.predict(data_dt.map(lambda p: p.features))\n",
    "actual = data.map(lambda p: p.label)\n",
    "true_vs_predicted_dt = actual.zip(preds)\n",
    "print \"Decision Tree predictions: \" + str(true_vs_predicted_dt.take(5))\n",
    "print \"Decision Tree depth: \" + str(dt_model.depth())\n",
    "print \"Decision Tree number of nodes: \" + str(dt_model.numNodes())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perfomance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set up performance metrics functions \n",
    "\n",
    "def squared_error(actual, pred):\n",
    "    return (pred - actual)**2\n",
    "\n",
    "def abs_error(actual, pred):\n",
    "    return np.abs(pred - actual)\n",
    "\n",
    "def squared_log_error(pred, actual):\n",
    "    return (np.log(pred + 1) - np.log(actual + 1))**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree - Mean Squared Error: 7.9139\n",
      "Decision Tree - Mean Absolute Error: 1.8721\n",
      "Decision Tree - Root Mean Squared Log Error: 0.1912\n"
     ]
    }
   ],
   "source": [
    "# compute performance metrics for decision tree model\n",
    "mse_dt = true_vs_predicted_dt.map(lambda (t, p): squared_error(t, p)).mean()\n",
    "mae_dt = true_vs_predicted_dt.map(lambda (t, p): abs_error(t, p)).mean()\n",
    "rmsle_dt = np.sqrt(true_vs_predicted_dt.map(lambda (t, p): squared_log_error(t, p)).mean())\n",
    "print \"Decision Tree - Mean Squared Error: %2.4f\" % mse_dt\n",
    "print \"Decision Tree - Mean Absolute Error: %2.4f\" % mae_dt\n",
    "print \"Decision Tree - Root Mean Squared Log Error: %2.4f\" % rmsle_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}