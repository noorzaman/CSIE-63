{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n",
    "from nltk.corpus import wordnet as wn\n",
    "import pandas as pd\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Crawler & Classifier\n",
    "- Convert this tutorial for our usecase [https://github.com/datacamp/datacamp_facebook_live_nlp/blob/master/NLP_FB_live_coding_soln.ipynb](https://github.com/datacamp/datacamp_facebook_live_nlp/blob/master/NLP_FB_live_coding_soln.ipynb)\n",
    "- [https://www.quora.com/How-can-I-extract-keywords-from-a-document-using-NLTK](https://www.quora.com/How-can-I-extract-keywords-from-a-document-using-NLTK)\n",
    "- [http://nlpforhackers.io/tf-idf/](http://nlpforhackers.io/tf-idf/)\n",
    "- [http://www.tiernok.com/posts/automated-keyword-extraction-tf-idf-rake-and-textrank.html](http://www.tiernok.com/posts/automated-keyword-extraction-tf-idf-rake-and-textrank.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keyword Extraction Algorithms\n",
    "1. TF-IDF\n",
    "2. TextRank [https://github.com/davidadamojr/TextRank](https://github.com/davidadamojr/TextRank)\n",
    "3. RAKE [https://github.com/aneesha/RAKE](https://github.com/aneesha/RAKE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### URL of site to scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# url = \"http://kutv.com/news/local/crash-on-i-84-bridge-in-riverdale\"\n",
    "url = \"http://money.cnn.com/2017/11/17/technology/tesla-semi-truck-reveal/index.html\"\n",
    "\n",
    "# url = \"http://www.inhabitat.com/the-worlds-first-space-nation-officially-in-orbit-with-new-satellite/\"\n",
    "# url = \"http://\" + \"www.dailymail.co.uk\" + \"/news/article-5099205/Notorious-serial-killer-Charles-Manson-dies-aged-83.html\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "requests.models.Response"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = requests.get(url)\n",
    "type(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning function to remove HTML Junk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_me(soup):\n",
    "    for s in soup(['script', 'style']):\n",
    "        s.decompose()\n",
    "    return ' '.join(soup.stripped_strings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove HTML from text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "html = r.text\n",
    "content = r.content.decode(encoding='UTF-8')\n",
    "soup = BeautifulSoup(r.content.decode(encoding='UTF-8'), \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# soup = BeautifulSoup(html, \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'Tesla reveals semi-truck and new sports car - Nov. 17, 2017 '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.title.string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114\n",
      "97\n",
      "['roy', 'kimmel', 'differs', 'startups', 'shkreli', 'policy', 'dodge', 'chiron', 'dapena', 'using', 'bank', 'adchoices', 'tang', 'martin', 'disclaimer', 'financial', 'people', 'senate', 'house', 'twitter', 'related', 'culture', 'peter', 'best', 'album', 'what', 'trending', 'peterdrives', 'announces', 'bonus', 'does', 'valdes', 'conditions', 'email', 'terms', 'business', 'here', 'wu', 'november', 'card', 'bugatti', 'surge', 'credit', 'jaw', 'arrived', 'com', 'jimmy', 'point', 'fees', 'apply', 'your', 'little', 'takes', 'service', 'privacy', 'top', 'dropping', 'interest', 'musk', 'offering', 'tax', 'account', 'challenger', 'this', 'bill', 'nextadvisor', 'future', 'cards', 'making', 'social', 'moore', 'pic', 'demon', 'accept', 'an', 'gadgets', 'intro', 'want', 'elon', 'partner', 'huge', 'pay', 'how', 'finding', 'charging', 'may', 'invitation', 'paid', 'feds', 'planners', 'a', 'seize', 'i', 'upset', 'savings', 'the', 'retirees']\n"
     ]
    }
   ],
   "source": [
    "link_list = []\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "for link in soup.find_all('a'):\n",
    "    link_tokens = re.findall('\\w+', link.get_text())\n",
    "    link_tokens = [token.lower().encode('utf-8') for token in link_tokens if token not in stopwords and token.isalpha()]\n",
    "    link_list = link_list + link_tokens\n",
    "\n",
    "print(len(link_list))    \n",
    "link_list = list(set(link_list))    \n",
    "print(len(link_list))\n",
    "print(link_list[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398\n",
      "398\n",
      "['by', 'continuing', 'use', 'site', 'agreeing', 'new', 'privacy', 'policy', 'terms', 'service', 'tesla', 'revealed', 'new', 'version', 'roadster', 'sports', 'car', 'go', 'stop', 'miles', 'hour', 'seconds', 'figure', 'would', 'make', 'fastest', 'accelerating', 'production', 'car', 'ever', 'that', 'tesla', 'unveiled', 'new', 'semi', 'truck', 'ceo', 'elon', 'musk', 'said', 'go', 'zero', 'five', 'seconds', 'empty', 'trailer', 'that', 'figure', 'usually', 'associated', 'luxury', 'sedans', 'big', 'trucks', 'with', 'full', 'load', 'truck', 'still', 'reach', 'speed', 'seconds', 'according', 'musk', 'much', 'faster', 'diesel', 'powered', 'truck', 'related', 'an', 'elon', 'musk', 'email', 'may', 'making', 'people', 'upset', 'only', 'talking', 'truck', 'speed', 'musk', 'mention', 'range', 'it', 'go', 'miles', 'full', 'load', 'highway', 'speeds', 'said', 'that', 'twice', 'distance', 'trucking', 'routes', 'musk', 'claimed']\n"
     ]
    }
   ],
   "source": [
    "p_list = []\n",
    "for link in soup.find_all('p'):\n",
    "    link_tokens = re.findall('\\w+', link.get_text())\n",
    "    link_tokens = [token.lower().encode('utf-8') for token in link_tokens if token not in stopwords and token.isalpha()]\n",
    "    p_list = p_list + link_tokens\n",
    "print(len(p_list))    \n",
    "# link_list = list(set(p_list))    \n",
    "print(len(p_list))\n",
    "print(p_list[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# text = clean_me(soup) \n",
    "# print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize words in text\n",
    "Step 1: Tokenize\n",
    "You want to tokenize your text, that is, split it into a list a words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tokens = re.findall('\\w+', text)\n",
    "# print len(tokens)\n",
    "# print(tokens[:25])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create tokenizer\n",
    "# Create tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Create tokenizer\n",
    "# tokenizer = RegexpTokenizer('\\w+')\n",
    "# # Create tokens\n",
    "# tokens = tokenizer.tokenize(text)\n",
    "# print(len(tokens))\n",
    "# tokens[:8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize new list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['by', 'continuing', 'use', 'site', 'agreeing', 'new', 'privacy', 'policy']\n",
      "398\n"
     ]
    }
   ],
   "source": [
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "tokens = [lemmatizer.lemmatize(token.lower()) for token in p_list]\n",
    "print tokens[:8]\n",
    "print(len(tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing stop words and alpha only characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'i', u'me', u'my', u'myself', u'we', u'our', u'ours', u'ourselves', u'you', u'your', u'yours', u'yourself', u'yourselves', u'he', u'him', u'his', u'himself', u'she', u'her', u'hers', u'herself', u'it', u'its', u'itself', u'they']\n",
      "['continuing', 'site', 'agreeing', 'privacy', 'policy', u'term', 'service', 'tesla', 'revealed', 'version', 'roadster', u'sport', 'stop', u'mile', 'hour', u'second', 'figure', 'would', 'make', 'fastest', 'accelerating', 'production', 'ever', 'tesla', 'unveiled']\n",
      "312\n"
     ]
    }
   ],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "print(stopwords[:25])\n",
    "tokens = [token for token in tokens if token not in stopwords and token.isalpha() and len(token) > 3]\n",
    "print tokens[:25]\n",
    "print(len(tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove words if it is in a link a href Tag on their site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tokens = [token for token in tokens if token not in link_list and len(token) > 3]\n",
    "# print tokens[:25]\n",
    "# print(len(tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Word  Count\n",
      "0           truck     10\n",
      "1            mile      9\n",
      "2           tesla      9\n",
      "3           jones      7\n",
      "4            musk      6\n",
      "5           right      6\n",
      "6           index      5\n",
      "7            said      5\n",
      "8        roadster      5\n",
      "9          second      5\n",
      "10          speed      5\n",
      "11        version      4\n",
      "12         diesel      4\n",
      "13         driver      4\n",
      "14       reserved      4\n",
      "15           semi      4\n",
      "16           also      3\n",
      "17           time      3\n",
      "18          still      3\n",
      "19           hour      3\n",
      "20        service      3\n",
      "21           make      3\n",
      "22      trademark      3\n",
      "23           cost      3\n",
      "24         system      3\n",
      "25          range      2\n",
      "26       standard      2\n",
      "27           seat      2\n",
      "28           elon      2\n",
      "29           opco      2\n",
      "..            ...    ...\n",
      "160       usually      1\n",
      "161    regardless      1\n",
      "162          year      1\n",
      "163       battery      1\n",
      "164   distributed      1\n",
      "165       running      1\n",
      "166          djia      1\n",
      "167  specifically      1\n",
      "168          side      1\n",
      "169    additional      1\n",
      "170    comparison      1\n",
      "171       bugatti      1\n",
      "172          news      1\n",
      "173    continuing      1\n",
      "174         sport      1\n",
      "175         shown      1\n",
      "176       network      1\n",
      "177       driving      1\n",
      "178      marketed      1\n",
      "179      research      1\n",
      "180       content      1\n",
      "181     autopilot      1\n",
      "182          ever      1\n",
      "183         email      1\n",
      "184       highway      1\n",
      "185      refilled      1\n",
      "186     available      1\n",
      "187      exchange      1\n",
      "188        screen      1\n",
      "189       typical      1\n",
      "\n",
      "[190 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py:8: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "new_words_ns = {}\n",
    "for t in tokens:\n",
    "    if t not in new_words_ns.keys():\n",
    "        new_words_ns[t] = 1\n",
    "    else:\n",
    "        new_words_ns[t] = int(new_words_ns[t]) + 1\n",
    "\n",
    "word_count = pd.DataFrame(new_words_ns.items(), columns=['Word', 'Count'])\\\n",
    "       .sort(['Count'], ascending=[False])\\\n",
    "       .reset_index(drop=True)\n",
    "print word_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>truck</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mile</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tesla</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jones</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>musk</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>right</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>index</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>said</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>roadster</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>second</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>speed</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>version</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>diesel</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>driver</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>reserved</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>semi</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>also</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>time</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>still</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>hour</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>service</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>make</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>trademark</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>cost</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>system</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>range</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>standard</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>seat</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>elon</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>opco</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>usually</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>regardless</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>year</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>battery</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>distributed</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>running</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>djia</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>specifically</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>side</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>additional</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>comparison</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>bugatti</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>news</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>continuing</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>sport</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>shown</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>network</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>driving</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>marketed</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>research</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>content</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>autopilot</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>ever</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>email</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>highway</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>refilled</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>available</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>exchange</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>screen</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>typical</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>190 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Word  Count\n",
       "0           truck     10\n",
       "1            mile      9\n",
       "2           tesla      9\n",
       "3           jones      7\n",
       "4            musk      6\n",
       "5           right      6\n",
       "6           index      5\n",
       "7            said      5\n",
       "8        roadster      5\n",
       "9          second      5\n",
       "10          speed      5\n",
       "11        version      4\n",
       "12         diesel      4\n",
       "13         driver      4\n",
       "14       reserved      4\n",
       "15           semi      4\n",
       "16           also      3\n",
       "17           time      3\n",
       "18          still      3\n",
       "19           hour      3\n",
       "20        service      3\n",
       "21           make      3\n",
       "22      trademark      3\n",
       "23           cost      3\n",
       "24         system      3\n",
       "25          range      2\n",
       "26       standard      2\n",
       "27           seat      2\n",
       "28           elon      2\n",
       "29           opco      2\n",
       "..            ...    ...\n",
       "160       usually      1\n",
       "161    regardless      1\n",
       "162          year      1\n",
       "163       battery      1\n",
       "164   distributed      1\n",
       "165       running      1\n",
       "166          djia      1\n",
       "167  specifically      1\n",
       "168          side      1\n",
       "169    additional      1\n",
       "170    comparison      1\n",
       "171       bugatti      1\n",
       "172          news      1\n",
       "173    continuing      1\n",
       "174         sport      1\n",
       "175         shown      1\n",
       "176       network      1\n",
       "177       driving      1\n",
       "178      marketed      1\n",
       "179      research      1\n",
       "180       content      1\n",
       "181     autopilot      1\n",
       "182          ever      1\n",
       "183         email      1\n",
       "184       highway      1\n",
       "185      refilled      1\n",
       "186     available      1\n",
       "187      exchange      1\n",
       "188        screen      1\n",
       "189       typical      1\n",
       "\n",
       "[190 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Cloud\n",
    "- http://nlpforhackers.io/word-clouds/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc = WordCloud().generate(' '.join(word_count))\n",
    " \n",
    "plt.imshow(wc, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create freq dist and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figures inline and set visualization style\n",
    "%matplotlib inline\n",
    "sns.set()\n",
    "\n",
    "# Create freq dist and plot\n",
    "freqdist1 = nltk.FreqDist(word_count)\n",
    "freqdist1.plot(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}